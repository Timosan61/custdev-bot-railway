from abc import ABC, abstractmethod
from typing import Dict, Optional, List
from aiogram import types
from aiogram.fsm.context import FSMContext
from loguru import logger
import os

from src.services.supabase_service import SupabaseService
from src.services.zep_service import ZepService
from src.services.voice_handler import VoiceMessageHandler
from src.utils.keyboards import get_cancel_keyboard
from src.state.user_states import ResearcherStates


class BaseResearcherAgent(ABC):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∞–≥–µ–Ω—Ç–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è —Å –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –¥–ª—è LLM –æ–ø–µ—Ä–∞—Ü–∏–π"""
    
    def __init__(self, supabase: SupabaseService, zep: ZepService):
        self.supabase = supabase
        self.zep = zep
        # Initialize voice handler with bot token
        bot_token = os.getenv("TELEGRAM_BOT_TOKEN")
        self.voice_handler = VoiceMessageHandler(bot_token=bot_token)
        
        # –°—Ç–∞—Ç–∏—á–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –ø–æ–ª—è
        self.static_questions = {
            "name": "–ö–∞–∫ –∫ –≤–∞–º –æ–±—Ä–∞—â–∞—Ç—å—Å—è?",
            "industry": "–í –∫–∞–∫–æ–π —Å—Ñ–µ—Ä–µ, –Ω–∏—à–µ –∏–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ?",
            "target": "–ö–æ–≥–æ / —á—Ç–æ –≤—ã –ø–ª–∞–Ω–∏—Ä—É–µ—Ç–µ –∏–∑—É—á–∞—Ç—å? –û–ø–∏—à–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞:\n1) –µ—Å–ª–∏ —ç—Ç–æ –ª—é–¥–∏ ‚Äî —Å–µ–≥–º–µ–Ω—Ç, —Ä–æ–ª—å, –≤–æ–∑—Ä–∞—Å—Ç, –≥–µ–æ–≥—Ä–∞—Ñ–∏—é;\n2) –µ—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å—ã –∏–ª–∏ –ø—Ä–æ–¥—É–∫—Ç ‚Äî –µ–≥–æ —ç—Ç–∞–ø—ã/—Ñ—É–Ω–∫—Ü–∏–∏, –≥–¥–µ ¬´–±–æ–ª–∏—Ç¬ª.",
            "hypotheses": "–ö–∞–∫–∏–µ —Ä–∞–±–æ—á–∏–µ –≥–∏–ø–æ—Ç–µ–∑—ã –∏–ª–∏ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è —Ö–æ—Ç–∏—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å? –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ ¬´–µ—Å–ª–∏ ‚Ä¶ —Ç–æ ‚Ä¶ ‚Üí –æ–∂–∏–¥–∞–µ–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç¬ª.",
            "style": "–í –∫–∞–∫–æ–º —Ç–æ–Ω–µ –æ–±—â–∞—Ç—å—Å—è —Å —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞–º–∏? –í—ã–±–µ—Ä–∏—Ç–µ –∏–ª–∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ —Å–≤–æ–π –≤–∞—Ä–∏–∞–Ω—Ç:\n‚Ä¢ –î—Ä—É–∂–µ–ª—é–±–Ω–æ, –Ω–∞ ¬´—Ç—ã¬ª\n‚Ä¢ –ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ-–¥–µ–ª–æ–≤–æ–π, –Ω–∞ ¬´–≤—ã¬ª\n‚Ä¢ –≠–∫—Å–ø–µ—Ä—Ç‚Äì—ç–∫—Å–ø–µ—Ä—Ç (—Ç–µ—Ä–º–∏–Ω—ã –¥–æ–ø—É—Å–∫–∞—é—Ç—Å—è)\n‚Ä¢ –õ–∞–π—Ç–æ–≤–æ —Å —é–º–æ—Ä–æ–º",
            "success_metric": "–ü–æ –∫–∞–∫–∏–º –º–µ—Ç—Ä–∏–∫–∞–º –≤—ã –ø–æ–π–º—ë—Ç–µ, —á—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ?\n–ù–∞–ø—Ä.: ¬´–Ω–∞–π—Ç–∏ 3 –∫–ª—é—á–µ–≤—ã–µ –º–æ—Ç–∏–≤–∞—Ü–∏–∏¬ª, ¬´–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å/–æ–ø—Ä–æ–≤–µ—Ä–≥–Ω—É—Ç—å 2 –≥–∏–ø–æ—Ç–µ–∑—ã¬ª.",
            "constraints": "–ï—Å—Ç—å –ª–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è: –≤—Ä–µ–º—è –∏–Ω—Ç–µ—Ä–≤—å—é, —Ç–µ–º—ã-—Ç–∞–±—É, —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (NDA/GDPR)?",
            "existing_data": "–ï—Å—Ç—å –ª–∏ —É–∂–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ/–∞–Ω–∞–ª–∏—Ç–∏–∫–∞, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ —Å—Ç–æ–∏—Ç –æ–ø–∏—Ä–∞—Ç—å—Å—è?\n–ú–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª (PDF, txt, docx) –∏–ª–∏ –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ."
        }
        
        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∏ –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        self.required_fields = ["name", "industry", "target", "hypotheses", "style"]
        self.optional_fields = ["success_metric", "constraints", "existing_data"]
        
        # –ü–æ—Ä—è–¥–æ–∫ –∑–∞–¥–∞–≤–∞–Ω–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤
        self.question_order = self.required_fields + self.optional_fields
        
        # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        self.fields_to_collect = self.static_questions
    
    @abstractmethod
    async def evaluate_answer_quality(self, field: str, answer: str) -> Dict:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å - –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞—Ö"""
        pass
    
    @abstractmethod
    async def generate_clarification(self, field: str, answer: str, missing_aspects: list) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å - –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞—Ö"""
        pass
    
    @abstractmethod
    async def generate_interview_brief(self, fields: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ—Ä–≤—å—é-–±—Ä–∏—Ñ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö - –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞—Ö"""
        pass
    
    @abstractmethod
    async def generate_instruction(self, fields: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –¥–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤ - –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞—Ö"""
        pass
    
    async def start_dialog(self, message: types.Message, state: FSMContext):
        """–ù–∞—á–∏–Ω–∞–µ—Ç –¥–∏–∞–ª–æ–≥ —Å –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–µ–º"""
        user_id = message.from_user.id
        
        # Create new interview
        interview = self.supabase.create_interview({"researcher_telegram_id": user_id})
        if not interview:
            await message.answer("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é")
            return
        interview_id = interview["id"]
        
        # Create Zep session
        zep_session_id = f"researcher_{user_id}_{interview_id}"
        await self.zep.create_session(zep_session_id, {
            "user_id": user_id,
            "interview_id": interview_id,
            "type": "researcher"
        })
        
        # Save to state
        await state.update_data(
            interview_id=interview_id,
            zep_session_id=zep_session_id,
            collected_fields={}
        )
        
        # Send welcome message and first question
        welcome_text = (
            "üî¨ <b>–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è</b>\n\n"
            "–ü—Ä–∏–≤–µ—Ç! –Ø –ø–æ–º–æ–≥—É –≤–∞–º —Å–æ–∑–¥–∞—Ç—å –∫–∞—Å—Ç–¥–µ–≤-–∏–Ω—Ç–µ—Ä–≤—å—é.\n\n"
            "–û—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ –º–æ–∏ –≤–æ–ø—Ä–æ—Å—ã –≤ —Å–≤–æ–±–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ —Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –≥–æ–ª–æ—Å–æ–º. "
            "–ö–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—Ç–µ, —Å–∫–∞–∂–∏—Ç–µ '—Ö–≤–∞—Ç–∏—Ç' –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è."
        )
        
        await message.answer(welcome_text, reply_markup=types.ReplyKeyboardRemove())
        
        # Ask first question from static questions
        first_field = self.question_order[0]
        first_question = self.static_questions[first_field]
        await message.answer(first_question)
        
        # Track current field index
        await state.update_data(current_field_index=0)
        
        # Save first question in state
        await state.update_data(last_question=first_question)
        
        # Log to Zep
        await self.zep.add_message(zep_session_id, "assistant", welcome_text)
        await self.zep.add_message(zep_session_id, "assistant", first_question)
    
    async def process_text_message(self, message: types.Message, state: FSMContext):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
        await self._process_message(message.text, message, state)
    
    async def process_voice_message(self, message: types.Message, state: FSMContext, bot):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
        # Send processing indicator
        processing_msg = await message.answer("üé§ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
        
        # Process voice message
        result = await self.voice_handler.process_voice_message(
            file_id=message.voice.file_id,
            duration=message.voice.duration
        )
        
        # Delete processing message
        await bot.delete_message(message.chat.id, processing_msg.message_id)
        
        if result["success"]:
            text = result["transcription"]
            logger.info(f"Voice transcribed: {text}")
            
            # Process the message
            await self._process_message(text, message, state)
        else:
            error = result.get("error", "Unknown error")
            logger.error(f"Voice processing failed: {error}")
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–º.")
    
    async def _process_message(self, text: str, message: types.Message, state: FSMContext):
        """–û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        data = await state.get_data()
        user_id = message.from_user.id
        interview_id = data.get("interview_id")
        zep_session_id = data.get("zep_session_id")
        collected_fields = data.get("collected_fields", {})
        current_field_index = data.get("current_field_index", 0)
        current_field = self.question_order[current_field_index] if current_field_index < len(self.question_order) else None
        is_clarification = data.get("is_clarification", False)
        
        logger.info(f"Processing message from user {user_id}: {text[:50]}...")
        logger.debug(f"Current field: {current_field}, Index: {current_field_index}")
        logger.debug(f"Is clarification: {is_clarification}")
        
        # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        if current_field in self.required_fields:
            text_lower = text.lower().strip()
            # –°–ø–∏—Å–æ–∫ —Å—Ç–æ–ø-—Å–ª–æ–≤ –¥–ª—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
            stop_words = ["–Ω–µ –∑–Ω–∞—é", "–Ω–µ–∑–Ω–∞—é", "–Ω–µ –ø–æ–Ω–∏–º–∞—é", "—Ö–∑", "—Ñ–∏–≥ –∑–Ω–∞–µ—Ç", "–ø–æ–Ω—è—Ç–∏—è –Ω–µ –∏–º–µ—é"]
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
            if any(stop_word in text_lower for stop_word in stop_words):
                logger.warning(f"Stop word detected in answer for {current_field}: {text}")
                await message.answer(
                    f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–∞–π—Ç–µ –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç. "
                    f"–≠—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–Ω—Ç–µ—Ä–≤—å—é –ø–æ–¥ –≤–∞—à–∏ –∑–∞–¥–∞—á–∏."
                )
                return
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –ø–æ–ª–µ–π
            min_lengths = {
                "industry": 5,
                "target": 10,
                "hypotheses": 15,
                "style": 5
            }
            
            if current_field in min_lengths and len(text.strip()) < min_lengths[current_field]:
                logger.warning(f"Answer too short for {current_field}: {len(text)} chars")
                await message.answer(
                    f"–í–∞—à –æ—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ."
                )
                return
        
        # Log user message to Zep
        await self.zep.add_message(zep_session_id, "user", text)
        
        # Check if user wants to finish
        if any(word in text.lower() for word in ["—Ö–≤–∞—Ç–∏—Ç", "–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ", "–≤—Å–µ", "—Å—Ç–æ–ø"]):
            # Check if we have all required fields
            missing_required = [f for f in self.required_fields if f not in collected_fields]
            if missing_required:
                await message.answer(
                    f"‚ùó –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –Ω—É–∂–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã.\n"
                    f"–û—Å—Ç–∞–ª–æ—Å—å –∑–∞–ø–æ–ª–Ω–∏—Ç—å: {', '.join([self.static_questions[f][:30] + '...' for f in missing_required[:2]])}\n\n"
                    f"–•–æ—Ç–∏—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å?"
                )
                return
            else:
                await self._finish_collection(message, state)
                return
        
        # Extract answer for current field
        if current_field:
            # Use field analyzer to check answer quality
            quality_result = await self.evaluate_answer_quality(current_field, text)
            
            logger.info(f"Quality evaluation for {current_field}: {quality_result}")
            
            if quality_result["is_complete"]:
                # Save the answer
                collected_fields[current_field] = quality_result["extracted_value"]
                await state.update_data(collected_fields=collected_fields, is_clarification=False)
                logger.info(f"Field {current_field} saved: {quality_result['extracted_value']}")
                
                # Move to next field
                next_index = current_field_index + 1
                
                # Skip optional fields if user said "no" or "skip"
                while next_index < len(self.question_order):
                    next_field = self.question_order[next_index]
                    if next_field in self.optional_fields and any(word in text.lower() for word in ["–Ω–µ—Ç", "–Ω–µ –Ω–∞–¥–æ", "–ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å", "skip"]):
                        logger.info(f"Skipping optional field: {next_field}")
                        next_index += 1
                    else:
                        break
                
                if next_index < len(self.question_order):
                    # Ask next static question
                    next_field = self.question_order[next_index]
                    next_question = self.static_questions[next_field]
                    await message.answer(next_question)
                    await self.zep.add_message(zep_session_id, "assistant", next_question)
                    await state.update_data(current_field_index=next_index, last_question=next_question)
                else:
                    # All questions asked
                    await self._finish_collection(message, state)
            else:
                # Need clarification
                if is_clarification:
                    # This was already a clarification attempt
                    # Only accept if quality check didn't fail completely
                    if quality_result.get("confidence", 0) > 0 or quality_result.get("extracted_value"):
                        # Accept the best we could extract
                        value_to_save = quality_result.get("extracted_value") or text
                        collected_fields[current_field] = value_to_save
                        await state.update_data(collected_fields=collected_fields, is_clarification=False)
                        logger.warning(f"Accepted answer after clarification for {current_field}: {value_to_save}")
                    else:
                        # Quality check completely failed - don't save garbage data
                        logger.error(f"Answer quality too poor for {current_field} even after clarification")
                        await message.answer(
                            "‚ùå –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å.\n"
                            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Ç–≤–µ—Ç–∏—Ç—å –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∏–ª–∏ —Å–∫–∞–∂–∏—Ç–µ '–ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å' –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –≤–æ–ø—Ä–æ—Å—É."
                        )
                        return
                    
                    # Move to next field
                    next_index = current_field_index + 1
                    if next_index < len(self.question_order):
                        next_field = self.question_order[next_index]
                        next_question = self.static_questions[next_field]
                        await message.answer(next_question)
                        await self.zep.add_message(zep_session_id, "assistant", next_question)
                        await state.update_data(current_field_index=next_index, last_question=next_question)
                    else:
                        await self._finish_collection(message, state)
                else:
                    # Generate clarification question
                    clarification = await self.generate_clarification(
                        current_field,
                        text,
                        quality_result["missing_aspects"]
                    )
                    await message.answer(clarification)
                    await self.zep.add_message(zep_session_id, "assistant", clarification)
                    await state.update_data(is_clarification=True, last_question=clarification)
    
    async def _finish_collection(self, message: types.Message, state: FSMContext):
        """–ó–∞–≤–µ—Ä—à–∞–µ—Ç —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ–∑–¥–∞–µ—Ç –∏–Ω—Ç–µ—Ä–≤—å—é"""
        data = await state.get_data()
        interview_id = data.get("interview_id")
        collected_fields = data.get("collected_fields", {})
        
        try:
            # Validate collected fields before generating brief
            validation_errors = []
            
            # Check required fields
            for field in self.required_fields:
                if field not in collected_fields or not collected_fields[field]:
                    validation_errors.append(f"–ü–æ–ª–µ '{field}' –Ω–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ")
                    continue
                    
                value = str(collected_fields[field]).strip().lower()
                
                # Check for garbage values
                garbage_values = ["–Ω–µ –∑–Ω–∞—é", "–Ω–µ–∑–Ω–∞—é", "–Ω–µ –ø–æ–Ω—è–ª", "–Ω–µ–ø–æ–Ω—è–ª", "–Ω–µ –ø–æ–Ω–∏–º–∞—é", "—Ö–∑", ""]
                if any(garbage in value for garbage in garbage_values):
                    validation_errors.append(f"–ü–æ–ª–µ '{field}' —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {collected_fields[field]}")
                
                # Check minimum length for critical fields
                if field in ["industry", "target", "hypotheses"] and len(collected_fields[field]) < 10:
                    validation_errors.append(f"–ü–æ–ª–µ '{field}' —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ: {collected_fields[field]}")
            
            if validation_errors:
                logger.error(f"Validation errors in collected fields: {validation_errors}")
                await message.answer(
                    "‚ùå –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ –≤—Å–µ –ø–æ–ª—è –±—ã–ª–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã:\n" +
                    "\n".join(f"‚Ä¢ {error}" for error in validation_errors) +
                    "\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ–∑–¥–∞—Ç—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–Ω–æ–≤–æ —Å –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏."
                )
                await state.clear()
                return
            
            # Generate interview brief
            interview_brief = await self.generate_interview_brief(collected_fields)
            
            # Extract instruction from brief (first message to respondent)
            # Simple extraction - find the section and get the content
            instruction_start = interview_brief.find("### 3. –ü–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç—É")
            if instruction_start != -1:
                instruction_text = interview_brief[instruction_start:]
                instruction_lines = instruction_text.split("\n")[2:]  # Skip header and empty line
                instruction = "\n".join(instruction_lines).strip()
            else:
                # Fallback to generating instruction the old way
                instruction = await self.generate_instruction(collected_fields)
            
            # Update interview
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º researcher_telegram_id –≤ fields –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            collected_fields["researcher_telegram_id"] = message.from_user.id
            
            update_data = {
                "status": "in_progress",
                "fields": collected_fields,
                "researcher_telegram_id": message.from_user.id  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ –≤–µ—Ä—Ö–Ω–µ–º —É—Ä–æ–≤–Ω–µ
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º instruction –µ—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            if instruction:
                update_data["instruction"] = instruction
                # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ fields –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                update_data["fields"]["instruction"] = instruction
            
            try:
                self.supabase.update_interview(interview_id, update_data)
            except Exception as e:
                logger.error(f"Error updating interview: {e}")
                await message.answer(
                    "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –±—Ä–∏—Ñ–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.\n"
                    "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
                )
                await state.clear()
                return
        
            # Generate interview link
            bot_username = (await message.bot.me()).username
            interview_link = f"https://t.me/{bot_username}?start=interview_{interview_id}"
            
            # –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∏–º–µ–Ω–∏
            researcher_name = collected_fields.get("name", "")
            greeting = f"–û—Ç–ª–∏—á–Ω–æ, {researcher_name}! " if researcher_name else ""
            
            # Send interview brief as a message
            brief_text = (
                f"‚úÖ <b>{greeting}–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ!</b>\n\n"
                f"<b>–°—Å—ã–ª–∫–∞ –¥–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤:</b>\n"
                f"{interview_link}\n\n"
                "üìÑ <b>–ò–Ω—Ç–µ—Ä–≤—å—é-–±—Ä–∏—Ñ:</b>\n\n"
            )
            
            # Send brief in parts to avoid message length limits
            await message.answer(brief_text, reply_markup=types.ReplyKeyboardRemove())
            
            # Send the interview brief
            await message.answer(interview_brief, parse_mode="Markdown")
            
            await state.clear()
            
        except Exception as e:
            logger.error(f"Error in _finish_collection: {e}", exc_info=True)
            await message.answer(
                "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.\n"
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
            )
            await state.clear()